{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2603af38-51d7-442d-867b-f263d41ca692",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "awkward version  1.10.3\n",
      "coffea version  0.7.21\n"
     ]
    }
   ],
   "source": [
    "import awkward as ak\n",
    "import numpy as np\n",
    "import time\n",
    "import coffea\n",
    "import uproot\n",
    "import hist\n",
    "import vector\n",
    "print(\"awkward version \", ak.__version__)\n",
    "print(\"coffea version \", coffea.__version__)\n",
    "from coffea import util, processor\n",
    "from coffea.nanoevents import NanoEventsFactory, NanoAODSchema, BaseSchema\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "from distributed.diagnostics.plugin import UploadDirectory\n",
    "import os\n",
    "from plot_utils import adjust_plot\n",
    "import matplotlib.pyplot as plt\n",
    "import correctionlib\n",
    "import re\n",
    "from distributed.diagnostics.plugin import UploadDirectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f105beef-6c92-47bf-bf46-ce6bc4b4ee6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def computeJER(pt, eta, rho, filename):\n",
    "    df = pd.read_csv( filename, delimiter='\\s+', skiprows = 1, names = ['eta_low','eta_high', 'rho_low', 'rho_high', 'unknown','pt_low','pt_high','par0','par1','par2','par3'])\n",
    "    \n",
    "    df = df[ (eta > df['eta_low']) &  (eta <= df['eta_high']) & (rho > df['rho_low']) & (rho <= df['rho_high'])  ]\n",
    "    p0 = df['par0']\n",
    "    p1 = df['par1']\n",
    "    p2 = df['par2']\n",
    "    p3 = df['par3']\n",
    "    x = pt\n",
    "    return np.sqrt(p0*np.abs(p0)/(x*x)+p1*p1*np.power(x,p3) + p2*p2)\n",
    "\n",
    "\n",
    "def GetPUSF(IOV, nTrueInt, var='nominal'):\n",
    "    ## json files from: https://gitlab.cern.ch/cms-nanoAOD/jsonpog-integration/-/tree/master/POG/LUM\n",
    "    fname = \"data/puWeights\"+IOV+\"UL.json.gz\"\n",
    "    hname = {\n",
    "        \"2016APV\": \"Collisions16_UltraLegacy_goldenJSON\",\n",
    "        \"2016\"   : \"Collisions16_UltraLegacy_goldenJSON\",\n",
    "        \"2017\"   : \"Collisions17_UltraLegacy_goldenJSON\",\n",
    "        \"2018\"   : \"Collisions18_UltraLegacy_goldenJSON\"\n",
    "    }\n",
    "    evaluator = correctionlib.CorrectionSet.from_file(fname)\n",
    "    return evaluator[hname[IOV]].evaluate(np.array(nTrueInt), var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5fba03bb-1192-4792-a429-7c506d53da63",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QCDProcessor(processor.ProcessorABC):\n",
    "    def __init__(self):\n",
    "        dataset_axis = hist.axis.StrCategory([], growth=True, name=\"dataset\", label=\"Primary dataset\")\n",
    "        frac_axis = hist.axis.Regular(300, 0, 2.0, name=\"frac\", label=r\"Fraction\")\n",
    "        ptgen_axis = hist.axis.Variable([200,260,350,460,550,650,760,13000], name=\"ptgen\", label=r\"p_{T,RECO} (GeV)\")\n",
    "        n_axis = hist.axis.Regular(5, 0, 5, name=\"n\", label=r\"Number\")\n",
    "        pt_axis = hist.axis.Variable([10 ,  11  , 12 ,  13  , 14  , 15 ,  17,\n",
    "       20  , 23  , 27   ,30  , 35   ,40  , 45 ,  57 ,  72  , 90  , 120 ,  150,\n",
    "       200  , 300 ,  400   ,550 ,  750 ,  1000 ,  1500  , 2000 ,  2500  , 3000,\n",
    "       3500 ,  4000  ,  5000   ,10000], name=\"pt\", label=r\"$p_{T}$ [GeV]\") #erased 4000 and 5000\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        pileup_axis = hist.axis.Variable([0, 10, 20, 30, 40, 50, 60, 70, 80],name = \"pileup\", label = r\"$\\mu$\" )     \n",
    "        pileup_fine_axis = hist.axis.Regular(30, 0, 40, name = 'pileup_fine', label = r\"$\\mu$\")\n",
    "        \n",
    "        rho_axis = hist.axis.Variable( [0, 7.47, 13.49, 19.52, 25.54, 31.57, 37.59, 90], \n",
    "                                      name = 'rho', label = r'$\\rho$')\n",
    "        rho_fine_axis = hist.axis.Regular(30, 0, 30, name = 'rho_fine', label = r\"$\\rho$\")\n",
    "        \n",
    "        \n",
    "        #eta_axis = hist.axis.Regular(15, -4,4, name = \"eta\", label = r\"$eta$\")\n",
    "        # eta_axis = hist.axis.Variable([0, 0.261, 0.522, 0.783,  1.044, 1.305, 1.566, 1.74, 1.93, 2.043, 2.172, 2.322, 2.5, 2.65, 2.853,\n",
    "        #                               2.964, 3.139, 5],name = \"eta\", label = r\"$\\eta$\")\n",
    "        #eta_axis = hist.axis.Variable([-5.191, -3.839, -3.489, -3.139, -2.964, -2.853, -2.65, -2.5, -2.322,-2.172,-2.043, -1.93, -1.74, -1.566,-1.305,-1.044 ,-0.783 ,-0.522, -0.261, 0, 0.261, 0.522, 0.783, 1.044, 1.305, 1.566, 1.74, 1.93, 2.043, 2.172, 2.322, 2.5, 2.65, 2.853,], name = \"eta\", label = r\"$\\eta$\")\n",
    "        \n",
    "        #eta_axis = hist.axis.Variable([0, 1.305,  2.5, 2.65, 2.853,\n",
    "                                        #5.191],name = \"eta\", label = r\"$\\eta$\")\n",
    "        \n",
    "        #eta_axis = hist.axis.Variable([ 0, 0.5, 0.8, 1.1, 1.3, 1.7, 1.9, 2.1, 2.3, 2.5, 2.8, 3, 3.2, 4.7],name = \"eta\", label = r\"$\\eta$\")\n",
    "        \n",
    "        eta_axis = hist.axis.Variable([ 0, 0.261, 0.522, 0.783, 1.044, 1.305, 1.566, 1.74, 1.93, 2.043, \n",
    "                                       2.172, 2.322, 2.5, 2.65, 2.853, 2.964, 3.139, 3.489, 3.839, 5.191],\n",
    "                                      name = \"eta\", label = r\"$\\eta$\")\n",
    "        \n",
    "        jer_axis = hist.axis.Regular(100, 0.995, 1.030, name = 'jer', label = \"JER\" )\n",
    "        \n",
    "        \n",
    "        h_njet_gen = hist.Hist(dataset_axis, n_axis, storage=\"weight\", label=\"Counts\")  #not in use\n",
    "        h_njet_reco = hist.Hist(dataset_axis, n_axis, storage=\"weight\", label=\"Counts\") #not in use\n",
    "        \n",
    "        h_pt_reco_over_gen = hist.Hist( dataset_axis, pt_axis, frac_axis, eta_axis, pileup_axis, storage = \"weight\", label = \"Counts\")\n",
    "        #h_pt_reco_over_raw = hist.Hist( dataset_axis, pt_raw_axis,n_axis, frac_axis, eta_axis, pileup_axis, storage = \"weight\", label = \"Counts\")\n",
    "        \n",
    "        \n",
    "        h_pileup_rho = hist.Hist(dataset_axis, pileup_fine_axis, rho_fine_axis, storage = \"weight\", label = \"Counts\") #used to make pileup vs rho plot\n",
    "        \n",
    "        \n",
    "        \n",
    "        #self.df = pd.read_csv( \"Summer19UL17_JRV2_MC_PtResolution_AK4PFchs.txt\", delimiter='\\s+', skiprows = 1, names = ['eta_low','eta_high', 'rho_low', 'rho_high', 'unknown','pt_low','pt_high','par0','par1','par2','par3'])\n",
    "        cutflow = {}\n",
    "\n",
    "        \n",
    "        self.hists = {\n",
    "            \"njet_gen\":h_njet_gen,\n",
    "            \"njet_reco\":h_njet_reco,\n",
    "            \"pt_reco_over_gen\": h_pt_reco_over_gen,\n",
    "            \"pileup_rho\": h_pileup_rho,\n",
    "            \"cutflow\": cutflow\n",
    "        }\n",
    "        \n",
    "    @property\n",
    "    def accumulator(self):\n",
    "        return self.hists\n",
    "    \n",
    "    def process(self, events):\n",
    "        dataset = events.metadata['dataset']\n",
    "        #print(dataset)\n",
    "        \n",
    "        if dataset not in self.hists[\"cutflow\"]:\n",
    "            self.hists[\"cutflow\"][dataset] = defaultdict(int)\n",
    "            \n",
    "        IOV = ('2016APV' if any(re.findall(r'HIPM', dataset))\n",
    "               else '2018' if any(re.findall(r'20UL18', dataset))\n",
    "               else '2017' if any(re.findall(r'20UL17', dataset))\n",
    "               else '2016')   \n",
    "        #print(IOV)\n",
    "\n",
    "\n",
    "        gen_vtx = events.GenVtx.z\n",
    "        reco_vtx = events.PV.z\n",
    "        \n",
    "        \n",
    "        # delta_z < 0.2 between reco and gen\n",
    "        events = events[np.abs(gen_vtx - reco_vtx) < 0.2]\n",
    "        \n",
    "        \n",
    "        # loose jet ID\n",
    "        events.Jet = events.Jet[events.Jet.jetId > 0]\n",
    "        \n",
    "\n",
    "        events = events[ak.num(events.Jet) > 0 ]\n",
    "        dataset = events.metadata['dataset']\n",
    "        \n",
    "        genjets = events.GenJet[:,0:3]\n",
    "        #genjets = events.GenJet[:,0:6]\n",
    "        recojets = genjets.nearest(events.Jet, threshold = 0.2)\n",
    "        \n",
    "        sel = ~ak.is_none(recojets, axis = 1)\n",
    "        \n",
    "        genjets = genjets[sel]\n",
    "        recojets = recojets[sel]\n",
    "             \n",
    "        ptresponse = recojets.pt/genjets.pt\n",
    "        \n",
    "        n_reco_vtx = events.PV.npvs #the number of primary vertices\n",
    "        n_pileup = events.Pileup.nPU #number of pileupss\n",
    "        rho = events.fixedGridRhoFastjetAll\n",
    "        pu_nTrueInt = events.Pileup.nTrueInt\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        sel = ~ak.is_none(ptresponse,axis=1)\n",
    "        ptresponse = ptresponse[sel]\n",
    "        recojets = recojets[sel]\n",
    "        genjets = genjets[sel]\n",
    "        \n",
    "        sel2 = ak.num(ptresponse) > 2\n",
    "        \n",
    "        recojets = recojets[sel2]\n",
    "        genjets = genjets[sel2]\n",
    "        \n",
    "        ptresponse = ptresponse[sel2]\n",
    "        ptresponse_raw = (recojets.pt * (1 - recojets.rawFactor))/genjets.pt\n",
    "        \n",
    "        n_reco_vtx = n_reco_vtx[sel2]\n",
    "        n_pileup = n_pileup[sel2]\n",
    "        rho = rho[sel2]\n",
    "        pu_nTrueInt = pu_nTrueInt[sel2]\n",
    "        \n",
    "        n_reco_vtx = ak.broadcast_arrays(n_reco_vtx, recojets.pt)[0]\n",
    "        n_pileup = ak.broadcast_arrays(n_pileup, recojets.pt)[0]\n",
    "        rho = ak.broadcast_arrays(rho, recojets.pt)[0]\n",
    "        pu_nTrueInt =   ak.broadcast_arrays(pu_nTrueInt, recojets.pt)[0]      \n",
    "        puWeight = GetPUSF(IOV, np.array(ak.flatten(pu_nTrueInt)))\n",
    "        \n",
    "        self.hists[\"pt_reco_over_gen\"].fill( dataset = dataset, pt = ak.flatten(genjets.pt),frac = ak.flatten(ptresponse), \n",
    "                                            eta = np.abs(ak.flatten(genjets.eta)), pileup = ak.flatten(n_pileup), weight = puWeight)\n",
    "        \n",
    "        #self.hists[\"pt_reco_over_raw\"].fill( dataset = dataset, pt_raw = ak.flatten(recojets.pt*(1 - recojets.rawFactor)), n = ak.flatten(n_reco_vtx) ,frac = ak.flatten(ptresponse_raw), eta = np.abs(ak.flatten(genjets.eta)), pileup = ak.flatten(n_pileup))\n",
    "        \n",
    "        self.hists[\"pileup_rho\"].fill(dataset = dataset, rho_fine = ak.flatten(rho), pileup_fine = ak.flatten(n_pileup), weight = puWeight)\n",
    "            \n",
    "        return self.hists\n",
    "    \n",
    "    def postprocess(self, accumulator):\n",
    "        return accumulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0351c9d3-911e-4d03-a7ec-082c080a5bcd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def runner(testing = True, eras = [\"2017\"], prependstr = 'root://xcache/', nworkers = 2 , client = None ):\n",
    "\n",
    "    \n",
    "    fileset = {}\n",
    "    \n",
    "    #datasets = [\"/RunIISummer20UL17NanoAODv9/QCD_Pt-15to7000_TuneCP5_Flat2018_13TeV_pythia8/NANOAODSIM/\",\"/RunIISummer20UL18NanoAODv9/QCD_Pt-15to7000_TuneCP5_Flat2018_13TeV_pythia8/\"]\n",
    "    for era in eras:\n",
    "        if era == '2017':\n",
    "            filename = 'samples/flatPU_JMENano_2017.txt'\n",
    "            metadata = '/RunIISummer20UL17NanoAODv9/QCD_Pt-15to7000_TuneCP5_Flat2018_13TeV_pythia8/NANOAODSIM/'\n",
    "        elif era == '2018':\n",
    "            filename = 'samples/flatPU_JMENano_2018.txt'\n",
    "            metadata = '/RunIISummer20UL18NanoAODv9/QCD_Pt-15to7000_TuneCP5_Flat2018_13TeV_pythia8/NANOAODSIM/'\n",
    "        else:\n",
    "            print(\"era is:\" + era)\n",
    "            print(\"This is Unknown era\")\n",
    "        with open(filename) as f:\n",
    "            files = [prependstr + i.rstrip() for i in f.readlines() if i[0] != '#']\n",
    "            fileset[metadata] =  files\n",
    "            \n",
    "            \n",
    "    if testing == True:\n",
    "        fileset[list(fileset.keys())[0]] = fileset[list(fileset.keys())[0]][:1]\n",
    "        \n",
    "        if client == None:\n",
    "            exe_args = {\n",
    "            \"skipbadfiles\": True,\n",
    "            \"schema\": NanoAODSchema,\n",
    "            \"workers\":1}\n",
    "\n",
    "            hists = processor.run_uproot_job(\n",
    "                            fileset,\n",
    "                            treename=\"Events\",\n",
    "                            processor_instance=QCDProcessor(),\n",
    "                            executor=processor.futures_executor, #.futures_executor,\n",
    "                            executor_args=exe_args,chunksize=1000000,\n",
    "                            maxchunks=5\n",
    "                        )\n",
    "        else:\n",
    "            exe_args = {\n",
    "                \"client\": client,\n",
    "                \"skipbadfiles\": True,\n",
    "                \"schema\": NanoAODSchema,\n",
    "                \"align_clusters\": True\n",
    "            }\n",
    "            hists = processor.run_uproot_job(\n",
    "                fileset,\n",
    "                treename=\"Events\",\n",
    "                processor_instance=QCDProcessor(),\n",
    "                executor=processor.dask_executor,\n",
    "                executor_args=exe_args,\n",
    "\n",
    "                maxchunks=10, chunksize = 100000\n",
    "                  )\n",
    "    else:\n",
    "        if client == None:\n",
    "            exe_args = {\n",
    "            \"skipbadfiles\": True,\n",
    "            \"schema\": NanoAODSchema,\n",
    "            \"workers\":nworkers}\n",
    "\n",
    "            hists = processor.run_uproot_job(\n",
    "                            fileset,\n",
    "                            treename=\"Events\",\n",
    "                            processor_instance=QCDProcessor(),\n",
    "                            executor=processor.iterative_executor, #.iterative_executor,#.futures_executor,\n",
    "                            executor_args=exe_args,\n",
    "                        )\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            # exe_args = {\n",
    "            #     \"client\": client,\n",
    "            #     \"skipbadfiles\": True,\n",
    "            #     \"schema\": NanoAODSchema,\n",
    "            #     \"align_clusters\": True\n",
    "            # }\n",
    "            # hists = processor.run_uproot_job(\n",
    "            #     fileset,\n",
    "            #     treename=\"Events\",\n",
    "            #     processor_instance=QCDProcessor(),\n",
    "            #     executor=processor.dask_executor,\n",
    "            #     executor_args=exe_args\n",
    "            #       )\n",
    "            executor = processor.DaskExecutor(client=client)\n",
    "            run = processor.Runner(executor=executor,\n",
    "                        schema= NanoAODSchema,\n",
    "                        savemetrics=False\n",
    "                      )\n",
    "\n",
    "            hists = run(fileset, \"Events\", processor_instance=QCDProcessor())\n",
    "            \n",
    "    \n",
    "    return hists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eba125bd-7cf8-4d27-a9d5-22a0618f0d10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "\n",
    "client = Client(\"tls://localhost:8786\")\n",
    "#client = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5534663-34b6-4ebe-a8a5-46b700fb585e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#year = 2017\n",
    "eras = [\"2018\"]\n",
    "testing = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a9f60a8-0870-47f1-84ea-b3f6d349ea28",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[#                                       ] | 4% Completed |  2.0s\r"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "XRootD error: [FATAL] Auth failed: No protocols left to try\nin file root://xcache//store/mc/RunIISummer20UL18NanoAODv9/QCD_Pt-15to7000_TuneCP5_Flat2018_13TeV_pythia8/NANOAODSIM/FlatPU0to75_20UL18JMENano_106X_upgrade2018_realistic_v16_L1v1-v1/2550000/A9601E87-1D7A-5947-960E-BA1F2F5A49D2.root",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m eraslist \u001b[38;5;241m=\u001b[39m [ [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2018\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m eras \u001b[38;5;129;01min\u001b[39;00m eraslist:\n\u001b[0;32m----> 3\u001b[0m     hists \u001b[38;5;241m=\u001b[39m \u001b[43mrunner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtesting\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtesting\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meras\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43meras\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprependstr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mroot://xcache/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnworkers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m testing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m      5\u001b[0m         fname_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_QCD_pt_response_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39meras[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJME\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "Cell \u001b[0;32mIn[12], line 91\u001b[0m, in \u001b[0;36mrunner\u001b[0;34m(testing, eras, prependstr, nworkers, client)\u001b[0m\n\u001b[1;32m     85\u001b[0m         executor \u001b[38;5;241m=\u001b[39m processor\u001b[38;5;241m.\u001b[39mDaskExecutor(client\u001b[38;5;241m=\u001b[39mclient)\n\u001b[1;32m     86\u001b[0m         run \u001b[38;5;241m=\u001b[39m processor\u001b[38;5;241m.\u001b[39mRunner(executor\u001b[38;5;241m=\u001b[39mexecutor,\n\u001b[1;32m     87\u001b[0m                     schema\u001b[38;5;241m=\u001b[39m NanoAODSchema,\n\u001b[1;32m     88\u001b[0m                     savemetrics\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     89\u001b[0m                   )\n\u001b[0;32m---> 91\u001b[0m         hists \u001b[38;5;241m=\u001b[39m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfileset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvents\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessor_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mQCDProcessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hists\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/coffea/processor/executor.py:1700\u001b[0m, in \u001b[0;36mRunner.__call__\u001b[0;34m(self, fileset, treename, processor_instance)\u001b[0m\n\u001b[1;32m   1679\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m   1680\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1681\u001b[0m     fileset: Dict,\n\u001b[1;32m   1682\u001b[0m     treename: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   1683\u001b[0m     processor_instance: ProcessorABC,\n\u001b[1;32m   1684\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Accumulatable:\n\u001b[1;32m   1685\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Run the processor_instance on a given fileset\u001b[39;00m\n\u001b[1;32m   1686\u001b[0m \n\u001b[1;32m   1687\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1697\u001b[0m \u001b[38;5;124;03m            An instance of a class deriving from ProcessorABC\u001b[39;00m\n\u001b[1;32m   1698\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1700\u001b[0m     wrapped_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfileset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessor_instance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtreename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1701\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_dataframes:\n\u001b[1;32m   1702\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m wrapped_out  \u001b[38;5;66;03m# not wrapped anymore\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/coffea/processor/executor.py:1782\u001b[0m, in \u001b[0;36mRunner.run\u001b[0;34m(self, fileset, processor_instance, treename)\u001b[0m\n\u001b[1;32m   1780\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m fileset\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1782\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfileset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtreename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1784\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessor_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1785\u001b[0m     pi_to_send \u001b[38;5;241m=\u001b[39m processor_instance\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/coffea/processor/executor.py:1734\u001b[0m, in \u001b[0;36mRunner.preprocess\u001b[0;34m(self, fileset, treename)\u001b[0m\n\u001b[1;32m   1731\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filemeta \u001b[38;5;129;01min\u001b[39;00m fileset:\n\u001b[1;32m   1732\u001b[0m     filemeta\u001b[38;5;241m.\u001b[39mmaybe_populate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata_cache)\n\u001b[0;32m-> 1734\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_preprocess_fileset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfileset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1735\u001b[0m fileset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filter_badfiles(fileset)\n\u001b[1;32m   1737\u001b[0m \u001b[38;5;66;03m# reverse fileset list to match the order of files as presented in version\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;66;03m# v0.7.4. This fixes tests using maxchunks.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/coffea/processor/executor.py:1461\u001b[0m, in \u001b[0;36mRunner._preprocess_fileset\u001b[0;34m(self, fileset)\u001b[0m\n\u001b[1;32m   1454\u001b[0m pre_executor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpre_executor\u001b[38;5;241m.\u001b[39mcopy(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpre_arg_override)\n\u001b[1;32m   1455\u001b[0m closure \u001b[38;5;241m=\u001b[39m partial(\n\u001b[1;32m   1456\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautomatic_retries,\n\u001b[1;32m   1457\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretries,\n\u001b[1;32m   1458\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskipbadfiles,\n\u001b[1;32m   1459\u001b[0m     partial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata_fetcher, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mxrootdtimeout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malign_clusters),\n\u001b[1;32m   1460\u001b[0m )\n\u001b[0;32m-> 1461\u001b[0m out, _ \u001b[38;5;241m=\u001b[39m \u001b[43mpre_executor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mto_get\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1462\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m out:\n\u001b[1;32m   1463\u001b[0m     item \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mpop()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/coffea/processor/executor.py:972\u001b[0m, in \u001b[0;36mDaskExecutor.__call__\u001b[0;34m(self, items, function, accumulator)\u001b[0m\n\u001b[1;32m    967\u001b[0m         \u001b[38;5;66;03m# FIXME: fancy widget doesn't appear, have to live with boring pbar\u001b[39;00m\n\u001b[1;32m    968\u001b[0m         progress(work, multi\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, notebook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    969\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    970\u001b[0m         accumulate(\n\u001b[1;32m    971\u001b[0m             [\n\u001b[0;32m--> 972\u001b[0m                 \u001b[43mwork\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    973\u001b[0m                 \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    974\u001b[0m                 \u001b[38;5;28;01melse\u001b[39;00m _decompress(work\u001b[38;5;241m.\u001b[39mresult())\n\u001b[1;32m    975\u001b[0m             ],\n\u001b[1;32m    976\u001b[0m             accumulator,\n\u001b[1;32m    977\u001b[0m         ),\n\u001b[1;32m    978\u001b[0m         \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m    979\u001b[0m     )\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m KilledWorker \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[1;32m    981\u001b[0m     baditem \u001b[38;5;241m=\u001b[39m key_to_item[ex\u001b[38;5;241m.\u001b[39mtask]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/distributed/client.py:282\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    281\u001b[0m     typ, exc, tb \u001b[38;5;241m=\u001b[39m result\n\u001b[0;32m--> 282\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcancelled\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/coffea/processor/executor.py:1367\u001b[0m, in \u001b[0;36mautomatic_retries\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1362\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1363\u001b[0m         \u001b[38;5;129;01mnot\u001b[39;00m skipbadfiles\n\u001b[1;32m   1364\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAuth failed\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(c) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m chain)\n\u001b[1;32m   1365\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m retries \u001b[38;5;241m==\u001b[39m retry_count\n\u001b[1;32m   1366\u001b[0m     ):\n\u001b[0;32m-> 1367\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m   1368\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempt \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (retry_count \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, retries \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m   1369\u001b[0m retry_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/coffea/processor/executor.py:1336\u001b[0m, in \u001b[0;36mautomatic_retries\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1334\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m retry_count \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m retries:\n\u001b[1;32m   1335\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1336\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1337\u001b[0m     \u001b[38;5;66;03m# catch xrootd errors and optionally skip\u001b[39;00m\n\u001b[1;32m   1338\u001b[0m     \u001b[38;5;66;03m# or retry to read the file\u001b[39;00m\n\u001b[1;32m   1339\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/coffea/processor/executor.py:1417\u001b[0m, in \u001b[0;36mmetadata_fetcher\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1413\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m   1414\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmetadata_fetcher\u001b[39m(\n\u001b[1;32m   1415\u001b[0m     xrootdtimeout: \u001b[38;5;28mint\u001b[39m, align_clusters: \u001b[38;5;28mbool\u001b[39m, item: FileMeta\n\u001b[1;32m   1416\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Accumulatable:\n\u001b[0;32m-> 1417\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m uproot\u001b[38;5;241m.\u001b[39mopen({item\u001b[38;5;241m.\u001b[39mfilename: \u001b[38;5;28;01mNone\u001b[39;00m}, timeout\u001b[38;5;241m=\u001b[39mxrootdtimeout) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m   1418\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1419\u001b[0m             tree \u001b[38;5;241m=\u001b[39m file[item\u001b[38;5;241m.\u001b[39mtreename]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/uproot/reading.py:141\u001b[0m, in \u001b[0;36mopen\u001b[0;34m()\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m uproot\u001b[38;5;241m.\u001b[39m_util\u001b[38;5;241m.\u001b[39misstr(file_path) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28mhasattr\u001b[39m(file_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(file_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseek\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    134\u001b[0m ):\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    136\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must be a string, pathlib.Path, an object with \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    137\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseek\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m methods, or a length-1 dict of \u001b[39m\u001b[38;5;124m{{\u001b[39m\u001b[38;5;124mfile_path: object_path}}, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    138\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mrepr\u001b[39m(path))\n\u001b[1;32m    139\u001b[0m     )\n\u001b[0;32m--> 141\u001b[0m file \u001b[38;5;241m=\u001b[39m ReadOnlyFile(\n\u001b[1;32m    142\u001b[0m     file_path,\n\u001b[1;32m    143\u001b[0m     object_cache\u001b[38;5;241m=\u001b[39mobject_cache,\n\u001b[1;32m    144\u001b[0m     array_cache\u001b[38;5;241m=\u001b[39marray_cache,\n\u001b[1;32m    145\u001b[0m     custom_classes\u001b[38;5;241m=\u001b[39mcustom_classes,\n\u001b[1;32m    146\u001b[0m     decompression_executor\u001b[38;5;241m=\u001b[39mdecompression_executor,\n\u001b[1;32m    147\u001b[0m     interpretation_executor\u001b[38;5;241m=\u001b[39minterpretation_executor,\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions,  \u001b[38;5;66;03m# NOTE: a comma after **options breaks Python 2\u001b[39;00m\n\u001b[1;32m    149\u001b[0m )\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m object_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m file\u001b[38;5;241m.\u001b[39mroot_directory\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/uproot/reading.py:580\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m()\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_before_create_source()\n\u001b[1;32m    577\u001b[0m Source, file_path \u001b[38;5;241m=\u001b[39m uproot\u001b[38;5;241m.\u001b[39m_util\u001b[38;5;241m.\u001b[39mfile_path_to_source_class(\n\u001b[1;32m    578\u001b[0m     file_path, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options\n\u001b[1;32m    579\u001b[0m )\n\u001b[0;32m--> 580\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_source \u001b[38;5;241m=\u001b[39m Source(\n\u001b[1;32m    581\u001b[0m     file_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options  \u001b[38;5;66;03m# NOTE: a comma after **options breaks Python 2\u001b[39;00m\n\u001b[1;32m    582\u001b[0m )\n\u001b[1;32m    584\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_before_get_chunks()\n\u001b[1;32m    586\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin_chunk_size\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m<\u001b[39m _file_header_fields_big\u001b[38;5;241m.\u001b[39msize:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/uproot/source/xrootd.py:453\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m()\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file_path \u001b[38;5;241m=\u001b[39m file_path\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_bytes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/uproot/source/xrootd.py:457\u001b[0m, in \u001b[0;36m_open\u001b[0;34m()\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_executor \u001b[38;5;241m=\u001b[39m uproot\u001b[38;5;241m.\u001b[39msource\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mResourceThreadPoolExecutor(\n\u001b[0;32m--> 457\u001b[0m         [\n\u001b[1;32m    458\u001b[0m             XRootDResource(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file_path, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout)\n\u001b[1;32m    459\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_workers)\n\u001b[1;32m    460\u001b[0m         ]\n\u001b[1;32m    461\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/uproot/source/xrootd.py:458\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_executor \u001b[38;5;241m=\u001b[39m uproot\u001b[38;5;241m.\u001b[39msource\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mResourceThreadPoolExecutor(\n\u001b[1;32m    457\u001b[0m         [\n\u001b[0;32m--> 458\u001b[0m             XRootDResource(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file_path, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout)\n\u001b[1;32m    459\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_workers)\n\u001b[1;32m    460\u001b[0m         ]\n\u001b[1;32m    461\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/uproot/source/xrootd.py:83\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m()\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file_path \u001b[38;5;241m=\u001b[39m file_path\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout \u001b[38;5;241m=\u001b[39m timeout\n\u001b[0;32m---> 83\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/uproot/source/xrootd.py:92\u001b[0m, in \u001b[0;36m_open\u001b[0;34m()\u001b[0m\n\u001b[1;32m     90\u001b[0m status, dummy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file_path, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_xrd_timeout())\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m status\u001b[38;5;241m.\u001b[39merror:\n\u001b[0;32m---> 92\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_xrd_error(status)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/uproot/source/xrootd.py:118\u001b[0m, in \u001b[0;36m_xrd_error\u001b[0;34m()\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m uproot\u001b[38;5;241m.\u001b[39m_util\u001b[38;5;241m.\u001b[39m_file_not_found(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file_path, status\u001b[38;5;241m.\u001b[39mmessage)\n\u001b[1;32m    117\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 118\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[1;32m    119\u001b[0m \u001b[38;5;250m                \u001b[39m\u001b[38;5;124;03m\"\"\"XRootD error: {}\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;124;03min file {}\"\"\"\u001b[39;00m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    121\u001b[0m                     status\u001b[38;5;241m.\u001b[39mmessage, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file_path\n\u001b[1;32m    122\u001b[0m                 )\n\u001b[1;32m    123\u001b[0m             )\n",
      "\u001b[0;31mOSError\u001b[0m: XRootD error: [FATAL] Auth failed: No protocols left to try\nin file root://xcache//store/mc/RunIISummer20UL18NanoAODv9/QCD_Pt-15to7000_TuneCP5_Flat2018_13TeV_pythia8/NANOAODSIM/FlatPU0to75_20UL18JMENano_106X_upgrade2018_realistic_v16_L1v1-v1/2550000/A9601E87-1D7A-5947-960E-BA1F2F5A49D2.root"
     ]
    }
   ],
   "source": [
    "eraslist = [ [\"2018\"]]\n",
    "for eras in eraslist:\n",
    "    hists = runner(testing = testing, eras = eras, prependstr = 'root://xcache/', nworkers = 4, client = client  )\n",
    "    if testing == True:\n",
    "        fname_out = 'test_QCD_pt_response_'+eras[0]+'JME'+'.pkl'\n",
    "    else:\n",
    "        fname_out = 'QCD_pt_response_'+eras[0]+'JME'+'.pkl'\n",
    "\n",
    "    with open(fname_out, \"wb\") as f:\n",
    "            pickle.dump( hists, f )\n",
    "\n",
    "    print(f\"The histograms are stored in {fname_out}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1586478-afa5-4fc7-931d-ad52bf83194d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
